{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94467416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress PyTorch UserWarning about DataLoader iterator re-creation\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76e33162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 0. Configuration ---\n",
    "CLEANED_CSV_PATH = 'metadata_with_features.csv' \n",
    "CHECKPOINT_DIR = './cnn_lstm_hybrid_checkpoints'\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 60 \n",
    "LEAD_COUNT = 12\n",
    "SAMPLES = 2500\n",
    "NUM_CLASSES = 3 \n",
    "NUM_CLINICAL_FEATURES = 8 \n",
    "HIDDEN_SIZE = 64\n",
    "LEARNING_RATE = 2e-4\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Focal Loss Function (For Imbalance) ---\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        if self.alpha is not None and not isinstance(self.alpha, torch.Tensor):\n",
    "            self.alpha = torch.tensor(self.alpha, dtype=torch.float32)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        log_p = F.log_softmax(inputs, dim=1)\n",
    "        log_p = log_p.gather(1, targets.view(-1, 1)).view(-1)\n",
    "        p = torch.exp(log_p)\n",
    "        loss = - (1 - p)**self.gamma * log_p\n",
    "        \n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.device != inputs.device:\n",
    "                self.alpha = self.alpha.to(inputs.device)\n",
    "            alpha_t = self.alpha.gather(0, targets.view(-1))\n",
    "            loss = alpha_t * loss\n",
    "            \n",
    "        return loss.mean() if self.reduction == 'mean' else loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Hybrid CNN-LSTM Model Architecture ---\n",
    "\n",
    "class CNNLSTM_FeatureExtractor(nn.Module):\n",
    "    \"\"\"Processes the raw ECG signal to generate a deep feature vector.\"\"\"\n",
    "    def __init__(self, hidden_size=HIDDEN_SIZE, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # CNN (Feature Extraction)\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(LEAD_COUNT, 32, kernel_size=15, stride=2, padding=7),\n",
    "            nn.BatchNorm1d(32), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2, padding=1),\n",
    "            \n",
    "            nn.Conv1d(32, 64, kernel_size=11, stride=2, padding=5),\n",
    "            nn.BatchNorm1d(64), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2, padding=1),\n",
    "            \n",
    "            nn.Conv1d(64, 128, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm1d(128), nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # LSTM (Temporal Context)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=128, hidden_size=hidden_size, num_layers=num_layers,\n",
    "            batch_first=True, bidirectional=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        cnn_out = self.cnn(x) \n",
    "        lstm_input = cnn_out.transpose(1, 2) \n",
    "        \n",
    "        _, (h_n, _) = self.lstm(lstm_input)\n",
    "        \n",
    "        final_state = torch.cat((h_n[-2, :, :], h_n[-1, :, :]), dim=1)\n",
    "        return final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalMultiInputHybridModel(nn.Module):\n",
    "    \"\"\"Combines deep features (CNN-LSTM output) and 8 handcrafted features.\"\"\"\n",
    "    def __init__(self, num_classes=NUM_CLASSES, num_clinical_features=NUM_CLINICAL_FEATURES):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.signal_extractor = CNNLSTM_FeatureExtractor(hidden_size=HIDDEN_SIZE)\n",
    "        \n",
    "        INPUT_SIZE = (2 * HIDDEN_SIZE) + num_clinical_features \n",
    "        \n",
    "        self.final_fc = nn.Sequential(\n",
    "            nn.Linear(INPUT_SIZE, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, signal, clinical_features):\n",
    "        deep_features = self.signal_extractor(signal) \n",
    "        \n",
    "        # Concatenate Deep Features with Handcrafted Features (ensuring float type)\n",
    "        combined_features = torch.cat((deep_features, clinical_features.float()), dim=1) \n",
    "        \n",
    "        return self.final_fc(combined_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Custom Dataset for Hybrid Input ---\n",
    "class HybridECGDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Load Signal from absolute path (processed_npy_path)\n",
    "        try:\n",
    "            signal = np.load(row['processed_npy_path']).T\n",
    "            if signal.shape != (LEAD_COUNT, SAMPLES):\n",
    "                signal = signal[:, :SAMPLES]\n",
    "            signal = np.nan_to_num(signal, nan=0.0)\n",
    "        except Exception: \n",
    "            signal = np.zeros((LEAD_COUNT, SAMPLES), dtype=np.float32)\n",
    "\n",
    "        # Load Features from absolute path (feature_path)\n",
    "        try:\n",
    "            features = np.load(row['feature_path'])\n",
    "        except Exception:\n",
    "            features = np.zeros(NUM_CLINICAL_FEATURES, dtype=np.float32)\n",
    "\n",
    "        label = {\"Low\": 0, \"Moderate\": 1, \"High\": 2}[row['severity_level']]\n",
    "        \n",
    "        return (torch.tensor(signal, dtype=torch.float32), \n",
    "                torch.tensor(features, dtype=torch.float32)), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af59753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Evaluation and Checkpointing Functions ---\n",
    "top_checkpoints = []\n",
    "N = 5\n",
    "def save_checkpoint(model, epoch, val_f1):\n",
    "    global top_checkpoints\n",
    "    path = os.path.join(CHECKPOINT_DIR, f\"hybrid_model_epoch{epoch}.pt\")\n",
    "    torch.save(model.state_dict(), path)\n",
    "    top_checkpoints.append((val_f1, path))\n",
    "    top_checkpoints.sort(reverse=True, key=lambda x: x[0])\n",
    "    if len(top_checkpoints) > N:\n",
    "        _, worst_path = top_checkpoints.pop()\n",
    "        if os.path.exists(worst_path):\n",
    "             os.remove(worst_path)\n",
    "    print(f\"Saved checkpoint: {path} (F1: {val_f1:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for (signal, features), y in dataloader:\n",
    "            signal, features = signal.to(DEVICE), features.to(DEVICE)\n",
    "            logits = model(signal, features)\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            y_pred.extend(preds)\n",
    "            y_true.extend(y.numpy())\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    acc = np.mean(np.array(y_true) == np.array(y_pred))\n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa6d0102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned metadata\n",
    "df = pd.read_csv(CLEANED_CSV_PATH)\n",
    "\n",
    "# Split the data\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['severity_level'], random_state=42)\n",
    "\n",
    "# --- Setup Weights and Sampler ---\n",
    "train_labels = train_df['severity_level'].map({'Low': 0, 'Moderate': 1, 'High': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focal Loss Alpha Weights\n",
    "class_weights_array = compute_class_weight(class_weight=\"balanced\", classes=np.unique(train_labels), y=train_labels)\n",
    "alpha_weights = torch.tensor(class_weights_array, dtype=torch.float32).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampler Weights (Inverse SQRT frequency for batch balance)\n",
    "train_labels_np = train_labels.values\n",
    "class_counts = train_df['severity_level'].value_counts().sort_index()\n",
    "num_samples = len(train_df)\n",
    "weights = 1.0 / np.sqrt(class_counts.values) \n",
    "sample_weights = weights[train_labels_np]\n",
    "\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=num_samples, replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88d19b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "train_loader = DataLoader(HybridECGDataset(train_df), batch_size=BATCH_SIZE, sampler=sampler)\n",
    "val_loader = DataLoader(HybridECGDataset(val_df), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c27e13eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model, Loss, Optimizer ---\n",
    "model = FinalMultiInputHybridModel(num_clinical_features=NUM_CLINICAL_FEATURES).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE) \n",
    "\n",
    "criterion = FocalLoss(alpha=alpha_weights, gamma=2.0) \n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Final Hybrid Training with Focal Loss...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60: 100%|██████████| 785/785 [16:01<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4168 | Val Acc: 0.4912 | Val F1: 0.5747\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch1.pt (F1: 0.5747)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/60: 100%|██████████| 785/785 [07:21<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4052 | Val Acc: 0.3499 | Val F1: 0.4208\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch2.pt (F1: 0.4208)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/60: 100%|██████████| 785/785 [04:05<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4168 | Val Acc: 0.4957 | Val F1: 0.5778\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch3.pt (F1: 0.5778)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/60: 100%|██████████| 785/785 [02:26<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3971 | Val Acc: 0.5053 | Val F1: 0.5877\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch4.pt (F1: 0.5877)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/60: 100%|██████████| 785/785 [02:00<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4048 | Val Acc: 0.4927 | Val F1: 0.5750\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch5.pt (F1: 0.5750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/60: 100%|██████████| 785/785 [01:49<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3857 | Val Acc: 0.5403 | Val F1: 0.6191\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch6.pt (F1: 0.6191)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/60: 100%|██████████| 785/785 [01:43<00:00,  7.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3790 | Val Acc: 0.4957 | Val F1: 0.5782\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch7.pt (F1: 0.5782)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/60: 100%|██████████| 785/785 [01:40<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3670 | Val Acc: 0.5575 | Val F1: 0.6344\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch8.pt (F1: 0.6344)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/60: 100%|██████████| 785/785 [01:39<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4003 | Val Acc: 0.3958 | Val F1: 0.4739\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch9.pt (F1: 0.4739)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/60: 100%|██████████| 785/785 [01:38<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3906 | Val Acc: 0.5250 | Val F1: 0.6052\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch10.pt (F1: 0.6052)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/60: 100%|██████████| 785/785 [01:45<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3574 | Val Acc: 0.5706 | Val F1: 0.6452\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch11.pt (F1: 0.6452)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/60: 100%|██████████| 785/785 [01:38<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3887 | Val Acc: 0.5750 | Val F1: 0.6489\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch12.pt (F1: 0.6489)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/60: 100%|██████████| 785/785 [01:37<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3743 | Val Acc: 0.5395 | Val F1: 0.6180\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch13.pt (F1: 0.6180)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/60: 100%|██████████| 785/785 [01:43<00:00,  7.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3552 | Val Acc: 0.6307 | Val F1: 0.6931\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch14.pt (F1: 0.6931)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/60: 100%|██████████| 785/785 [01:44<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3724 | Val Acc: 0.5330 | Val F1: 0.6120\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch15.pt (F1: 0.6120)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/60: 100%|██████████| 785/785 [01:44<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3712 | Val Acc: 0.5993 | Val F1: 0.6688\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch16.pt (F1: 0.6688)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/60: 100%|██████████| 785/785 [01:44<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3390 | Val Acc: 0.5298 | Val F1: 0.6084\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch17.pt (F1: 0.6084)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/60: 100%|██████████| 785/785 [01:37<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3347 | Val Acc: 0.5951 | Val F1: 0.6647\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch18.pt (F1: 0.6647)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/60: 100%|██████████| 785/785 [01:37<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3603 | Val Acc: 0.4347 | Val F1: 0.5165\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch19.pt (F1: 0.5165)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/60: 100%|██████████| 785/785 [01:44<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3256 | Val Acc: 0.7715 | Val F1: 0.7890\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch20.pt (F1: 0.7890)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/60: 100%|██████████| 785/785 [01:37<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3253 | Val Acc: 0.7177 | Val F1: 0.7558\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch21.pt (F1: 0.7558)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/60: 100%|██████████| 785/785 [01:38<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2943 | Val Acc: 0.6232 | Val F1: 0.6871\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch22.pt (F1: 0.6871)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/60: 100%|██████████| 785/785 [01:38<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3214 | Val Acc: 0.7670 | Val F1: 0.7883\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch23.pt (F1: 0.7883)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/60: 100%|██████████| 785/785 [01:38<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2949 | Val Acc: 0.6442 | Val F1: 0.7026\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch24.pt (F1: 0.7026)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/60: 100%|██████████| 785/785 [01:37<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2859 | Val Acc: 0.6577 | Val F1: 0.7131\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch25.pt (F1: 0.7131)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/60: 100%|██████████| 785/785 [01:38<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2844 | Val Acc: 0.7290 | Val F1: 0.7628\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch26.pt (F1: 0.7628)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/60: 100%|██████████| 785/785 [01:37<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2579 | Val Acc: 0.7683 | Val F1: 0.7905\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch27.pt (F1: 0.7905)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/60: 100%|██████████| 785/785 [01:47<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2186 | Val Acc: 0.7814 | Val F1: 0.7992\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch28.pt (F1: 0.7992)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/60: 100%|██████████| 785/785 [01:44<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2138 | Val Acc: 0.7706 | Val F1: 0.7926\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch29.pt (F1: 0.7926)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/60: 100%|██████████| 785/785 [01:44<00:00,  7.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2092 | Val Acc: 0.7478 | Val F1: 0.7786\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch30.pt (F1: 0.7786)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/60: 100%|██████████| 785/785 [01:37<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2233 | Val Acc: 0.7455 | Val F1: 0.7775\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch31.pt (F1: 0.7775)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/60: 100%|██████████| 785/785 [01:37<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2083 | Val Acc: 0.7728 | Val F1: 0.7950\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch32.pt (F1: 0.7950)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/60: 100%|██████████| 785/785 [01:37<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2149 | Val Acc: 0.7774 | Val F1: 0.7975\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch33.pt (F1: 0.7975)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/60: 100%|██████████| 785/785 [01:38<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2193 | Val Acc: 0.7929 | Val F1: 0.8079\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch34.pt (F1: 0.8079)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/60: 100%|██████████| 785/785 [01:39<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2078 | Val Acc: 0.7741 | Val F1: 0.7968\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch35.pt (F1: 0.7968)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/60: 100%|██████████| 785/785 [01:41<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2041 | Val Acc: 0.7766 | Val F1: 0.7978\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch36.pt (F1: 0.7978)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/60: 100%|██████████| 785/785 [01:40<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2052 | Val Acc: 0.7827 | Val F1: 0.8029\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch37.pt (F1: 0.8029)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/60: 100%|██████████| 785/785 [01:39<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2104 | Val Acc: 0.7943 | Val F1: 0.8084\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch38.pt (F1: 0.8084)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/60: 100%|██████████| 785/785 [01:38<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2036 | Val Acc: 0.7954 | Val F1: 0.8092\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch39.pt (F1: 0.8092)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/60: 100%|██████████| 785/785 [01:38<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1714 | Val Acc: 0.7898 | Val F1: 0.8067\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch40.pt (F1: 0.8067)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/60: 100%|██████████| 785/785 [01:37<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1980 | Val Acc: 0.7819 | Val F1: 0.8019\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch41.pt (F1: 0.8019)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/60: 100%|██████████| 785/785 [01:36<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1984 | Val Acc: 0.7808 | Val F1: 0.8013\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch42.pt (F1: 0.8013)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/60: 100%|██████████| 785/785 [01:37<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1857 | Val Acc: 0.7828 | Val F1: 0.8023\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch43.pt (F1: 0.8023)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/60: 100%|██████████| 785/785 [01:37<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1863 | Val Acc: 0.7968 | Val F1: 0.8101\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch44.pt (F1: 0.8101)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/60: 100%|██████████| 785/785 [01:37<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1756 | Val Acc: 0.8035 | Val F1: 0.8149\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch45.pt (F1: 0.8149)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/60: 100%|██████████| 785/785 [01:37<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1625 | Val Acc: 0.8023 | Val F1: 0.8157\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch46.pt (F1: 0.8157)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/60: 100%|██████████| 785/785 [01:37<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1858 | Val Acc: 0.7835 | Val F1: 0.8029\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch47.pt (F1: 0.8029)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/60: 100%|██████████| 785/785 [01:49<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1611 | Val Acc: 0.7962 | Val F1: 0.8107\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch48.pt (F1: 0.8107)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/60: 100%|██████████| 785/785 [02:00<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1607 | Val Acc: 0.8094 | Val F1: 0.8187\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch49.pt (F1: 0.8187)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/60: 100%|██████████| 785/785 [05:40<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1474 | Val Acc: 0.7994 | Val F1: 0.8122\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch50.pt (F1: 0.8122)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/60: 100%|██████████| 785/785 [06:53<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1545 | Val Acc: 0.7938 | Val F1: 0.8096\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch51.pt (F1: 0.8096)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/60: 100%|██████████| 785/785 [03:53<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1701 | Val Acc: 0.7898 | Val F1: 0.8056\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch52.pt (F1: 0.8056)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/60: 100%|██████████| 785/785 [02:43<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1463 | Val Acc: 0.7873 | Val F1: 0.8042\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch53.pt (F1: 0.8042)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/60: 100%|██████████| 785/785 [01:57<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1527 | Val Acc: 0.8070 | Val F1: 0.8172\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch54.pt (F1: 0.8172)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/60: 100%|██████████| 785/785 [01:58<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1355 | Val Acc: 0.8107 | Val F1: 0.8188\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch55.pt (F1: 0.8188)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/60: 100%|██████████| 785/785 [01:46<00:00,  7.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1502 | Val Acc: 0.8059 | Val F1: 0.8154\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch56.pt (F1: 0.8154)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/60: 100%|██████████| 785/785 [01:45<00:00,  7.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1609 | Val Acc: 0.8102 | Val F1: 0.8184\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch57.pt (F1: 0.8184)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/60: 100%|██████████| 785/785 [01:49<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1618 | Val Acc: 0.8086 | Val F1: 0.8182\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch58.pt (F1: 0.8182)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/60: 100%|██████████| 785/785 [01:46<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1459 | Val Acc: 0.8133 | Val F1: 0.8194\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch59.pt (F1: 0.8194)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/60: 100%|██████████| 785/785 [01:46<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1643 | Val Acc: 0.8139 | Val F1: 0.8209\n",
      "Saved checkpoint: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch60.pt (F1: 0.8209)\n"
     ]
    }
   ],
   "source": [
    "# --- Training Loop ---\n",
    "print(\"Starting Final Hybrid Training with Focal Loss...\")\n",
    "best_val_f1 = 0.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for (x_signal, x_features), y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        x_signal, x_features, y = x_signal.to(DEVICE), x_features.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(x_signal, x_features)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        if torch.isnan(loss): continue\n",
    "                \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    val_acc, val_f1 = hybrid_evaluate(model, val_loader)\n",
    "    \n",
    "    scheduler.step(val_f1)\n",
    "\n",
    "    print(f\"Loss: {avg_loss:.4f} | Val Acc: {val_acc:.4f} | Val F1: {val_f1:.4f}\")\n",
    "    save_checkpoint(model, epoch + 1, val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ed44a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Evaluation ---\n",
      "Loaded best model from: ./cnn_lstm_hybrid_checkpoints\\hybrid_model_epoch60.pt\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Final Evaluation ---\")\n",
    "if top_checkpoints:\n",
    "    best_path = top_checkpoints[0][1]\n",
    "    model.load_state_dict(torch.load(best_path))\n",
    "    print(f\"Loaded best model from: {best_path}\")\n",
    "\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for (x_signal, x_features), y in val_loader:\n",
    "        x_signal, x_features = x_signal.to(DEVICE), x_features.to(DEVICE)\n",
    "        out = model(x_signal, x_features)\n",
    "        preds = torch.argmax(out, dim=1).cpu().numpy()\n",
    "        y_pred.extend(preds)\n",
    "        y_true.extend(y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18605efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Classification Report (Hybrid CNN-LSTM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.91      0.88      0.90      5493\n",
      "    Moderate       0.20      0.13      0.16       190\n",
      "        High       0.29      0.40      0.33       593\n",
      "\n",
      "    accuracy                           0.81      6276\n",
      "   macro avg       0.46      0.47      0.46      6276\n",
      "weighted avg       0.83      0.81      0.82      6276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal Classification Report (Hybrid CNN-LSTM):\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Low\", \"Moderate\", \"High\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a28fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Classification Report Interpreting:\n",
    "\n",
    "Support: total number of samples in the validation set\n",
    "Weighted Average:   F1 score weighted by the size of each class, in this case will always be high due to 'Low' class dominating the score. Poor \n",
    "                    metric for imbalanced data.\n",
    "Macro Average:      Calculates metric for each class independently, and then takes unweighted arithmetic mean of the values.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaea122",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The major weakness is the Recall for Moderate (0.13) and High (0.40), meaning the model misses most of the severe cases.\n",
    "\n",
    "IMPROVE USING:\n",
    "\n",
    "A. Data Augmentation\n",
    "You've trained on the same data 60 times. Augmentation creates new, slightly varied training examples without collecting new data, directly \n",
    "addressing the data scarcity for minority classes.\n",
    "Action: \n",
    "    Implement Time-Series Augmentations directly in your HybridECGDataset.__getitem__ method (applied only to training data). \n",
    "    Useful techniques include:\n",
    "        Time-Warping: Slightly stretching or compressing the signal.\n",
    "        Scaling/Jittering: Randomly scaling the amplitude or adding Gaussian noise.\n",
    "        Random Lead Dropout: Temporarily setting one or two leads to zero to improve robustness.\n",
    "\n",
    "B. Hyperparameter Tuning (Focal Loss Gamma)\n",
    "The F1 is high, but the Recall is low, suggesting the model is still finding it \"easy\" to achieve a good loss value without correctly classifying\n",
    "the hardest samples.\n",
    "Action: \n",
    "    Increase the Focal Loss gamma parameter (currently 2) to 3 or 4. A higher gamma further penalizes predictions where the model is confident \n",
    "    but wrong, forcing it to focus more intensely on the hardest, most ambiguous (often minority) samples.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947312dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# from tqdm import tqdm\n",
    "# from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "# from sklearn.metrics import f1_score, classification_report\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "# import warnings\n",
    "\n",
    "# # Suppress PyTorch UserWarning about DataLoader iterator re-creation\n",
    "# warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# # --- 0. Configuration ---\n",
    "# CLEANED_CSV_PATH = 'metadata_with_features.csv' \n",
    "# CHECKPOINT_DIR = './cnn_lstm_hybrid_checkpoints'\n",
    "# os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# BATCH_SIZE = 32\n",
    "# EPOCHS = 60 \n",
    "# LEAD_COUNT = 12\n",
    "# SAMPLES = 2500\n",
    "# NUM_CLASSES = 3 \n",
    "# NUM_CLINICAL_FEATURES = 8 \n",
    "# HIDDEN_SIZE = 64\n",
    "# LEARNING_RATE = 2e-4\n",
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# DEVICE\n",
    "\n",
    "# # --- 1. Focal Loss Function (For Imbalance) ---\n",
    "# class FocalLoss(nn.Module):\n",
    "#     def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "#         super().__init__()\n",
    "#         self.alpha = alpha\n",
    "#         self.gamma = gamma\n",
    "#         self.reduction = reduction\n",
    "#         if self.alpha is not None and not isinstance(self.alpha, torch.Tensor):\n",
    "#             self.alpha = torch.tensor(self.alpha, dtype=torch.float32)\n",
    "\n",
    "#     def forward(self, inputs, targets):\n",
    "#         log_p = F.log_softmax(inputs, dim=1)\n",
    "#         log_p = log_p.gather(1, targets.view(-1, 1)).view(-1)\n",
    "#         p = torch.exp(log_p)\n",
    "#         loss = - (1 - p)**self.gamma * log_p\n",
    "        \n",
    "#         if self.alpha is not None:\n",
    "#             if self.alpha.device != inputs.device:\n",
    "#                 self.alpha = self.alpha.to(inputs.device)\n",
    "#             alpha_t = self.alpha.gather(0, targets.view(-1))\n",
    "#             loss = alpha_t * loss\n",
    "            \n",
    "#         return loss.mean() if self.reduction == 'mean' else loss.sum()\n",
    "\t\t\n",
    "# # --- 2. Hybrid CNN-LSTM Model Architecture ---\n",
    "\n",
    "# class CNNLSTM_FeatureExtractor(nn.Module):\n",
    "#     \"\"\"Processes the raw ECG signal to generate a deep feature vector.\"\"\"\n",
    "#     def __init__(self, hidden_size=HIDDEN_SIZE, num_layers=1):\n",
    "#         super().__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "        \n",
    "#         # CNN (Feature Extraction)\n",
    "#         self.cnn = nn.Sequential(\n",
    "#             nn.Conv1d(LEAD_COUNT, 32, kernel_size=15, stride=2, padding=7),\n",
    "#             nn.BatchNorm1d(32), nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool1d(kernel_size=3, stride=2, padding=1),\n",
    "            \n",
    "#             nn.Conv1d(32, 64, kernel_size=11, stride=2, padding=5),\n",
    "#             nn.BatchNorm1d(64), nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool1d(kernel_size=3, stride=2, padding=1),\n",
    "            \n",
    "#             nn.Conv1d(64, 128, kernel_size=7, stride=2, padding=3),\n",
    "#             nn.BatchNorm1d(128), nn.ReLU(inplace=True)\n",
    "#         )\n",
    "        \n",
    "#         # LSTM (Temporal Context)\n",
    "#         self.lstm = nn.LSTM(\n",
    "#             input_size=128, hidden_size=hidden_size, num_layers=num_layers,\n",
    "#             batch_first=True, bidirectional=True\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         cnn_out = self.cnn(x) \n",
    "#         lstm_input = cnn_out.transpose(1, 2) \n",
    "        \n",
    "#         _, (h_n, _) = self.lstm(lstm_input)\n",
    "        \n",
    "#         final_state = torch.cat((h_n[-2, :, :], h_n[-1, :, :]), dim=1)\n",
    "#         return final_state\n",
    "\t\t\n",
    "# class FinalMultiInputHybridModel(nn.Module):\n",
    "#     \"\"\"Combines deep features (CNN-LSTM output) and 8 handcrafted features.\"\"\"\n",
    "#     def __init__(self, num_classes=NUM_CLASSES, num_clinical_features=NUM_CLINICAL_FEATURES):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.signal_extractor = CNNLSTM_FeatureExtractor(hidden_size=HIDDEN_SIZE)\n",
    "        \n",
    "#         INPUT_SIZE = (2 * HIDDEN_SIZE) + num_clinical_features \n",
    "        \n",
    "#         self.final_fc = nn.Sequential(\n",
    "#             nn.Linear(INPUT_SIZE, 64),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(64, num_classes)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, signal, clinical_features):\n",
    "#         deep_features = self.signal_extractor(signal) \n",
    "        \n",
    "#         # Concatenate Deep Features with Handcrafted Features (ensuring float type)\n",
    "#         combined_features = torch.cat((deep_features, clinical_features.float()), dim=1) \n",
    "        \n",
    "#         return self.final_fc(combined_features)\n",
    "\t\t\n",
    "# # --- 3. Custom Dataset for Hybrid Input ---\n",
    "# class HybridECGDataset(Dataset):\n",
    "#     def __init__(self, df):\n",
    "#         self.df = df.reset_index(drop=True)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.df)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         row = self.df.iloc[idx]\n",
    "        \n",
    "#         # Load Signal from absolute path (processed_npy_path)\n",
    "#         try:\n",
    "#             signal = np.load(row['processed_npy_path']).T\n",
    "#             if signal.shape != (LEAD_COUNT, SAMPLES):\n",
    "#                 signal = signal[:, :SAMPLES]\n",
    "#             signal = np.nan_to_num(signal, nan=0.0)\n",
    "#         except Exception: \n",
    "#             signal = np.zeros((LEAD_COUNT, SAMPLES), dtype=np.float32)\n",
    "\n",
    "#         # Load Features from absolute path (feature_path)\n",
    "#         try:\n",
    "#             features = np.load(row['feature_path'])\n",
    "#         except Exception:\n",
    "#             features = np.zeros(NUM_CLINICAL_FEATURES, dtype=np.float32)\n",
    "\n",
    "#         label = {\"Low\": 0, \"Moderate\": 1, \"High\": 2}[row['severity_level']]\n",
    "        \n",
    "#         return (torch.tensor(signal, dtype=torch.float32), \n",
    "#                 torch.tensor(features, dtype=torch.float32)), label\n",
    "\t\t\t\t\n",
    "# # --- 4. Evaluation and Checkpointing Functions ---\n",
    "# top_checkpoints = []\n",
    "# N = 5\n",
    "# def save_checkpoint(model, epoch, val_f1):\n",
    "#     global top_checkpoints\n",
    "#     path = os.path.join(CHECKPOINT_DIR, f\"hybrid_model_epoch{epoch}.pt\")\n",
    "#     torch.save(model.state_dict(), path)\n",
    "#     top_checkpoints.append((val_f1, path))\n",
    "#     top_checkpoints.sort(reverse=True, key=lambda x: x[0])\n",
    "#     if len(top_checkpoints) > N:\n",
    "#         _, worst_path = top_checkpoints.pop()\n",
    "#         if os.path.exists(worst_path):\n",
    "#              os.remove(worst_path)\n",
    "#     print(f\"Saved checkpoint: {path} (F1: {val_f1:.4f})\")\n",
    "\t\n",
    "# def hybrid_evaluate(model, dataloader):\n",
    "#     model.eval()\n",
    "#     y_true, y_pred = [], []\n",
    "#     with torch.no_grad():\n",
    "#         for (signal, features), y in dataloader:\n",
    "#             signal, features = signal.to(DEVICE), features.to(DEVICE)\n",
    "#             logits = model(signal, features)\n",
    "#             preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "#             y_pred.extend(preds)\n",
    "#             y_true.extend(y.numpy())\n",
    "#     f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "#     acc = np.mean(np.array(y_true) == np.array(y_pred))\n",
    "#     return acc, f1\n",
    "\t\n",
    "# # Load the cleaned metadata\n",
    "# df = pd.read_csv(CLEANED_CSV_PATH)\n",
    "\n",
    "# # Split the data\n",
    "# train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['severity_level'], random_state=42)\n",
    "\n",
    "# # --- Setup Weights and Sampler ---\n",
    "# train_labels = train_df['severity_level'].map({'Low': 0, 'Moderate': 1, 'High': 2})\n",
    "\n",
    "# # Focal Loss Alpha Weights\n",
    "# class_weights_array = compute_class_weight(class_weight=\"balanced\", classes=np.unique(train_labels), y=train_labels)\n",
    "# alpha_weights = torch.tensor(class_weights_array, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "# # Sampler Weights (Inverse SQRT frequency for batch balance)\n",
    "# train_labels_np = train_labels.values\n",
    "# class_counts = train_df['severity_level'].value_counts().sort_index()\n",
    "# num_samples = len(train_df)\n",
    "# weights = 1.0 / np.sqrt(class_counts.values) \n",
    "# sample_weights = weights[train_labels_np]\n",
    "\n",
    "# sampler = WeightedRandomSampler(weights=sample_weights, num_samples=num_samples, replacement=True)\n",
    "\n",
    "# # DataLoaders\n",
    "# train_loader = DataLoader(HybridECGDataset(train_df), batch_size=BATCH_SIZE, sampler=sampler)\n",
    "# val_loader = DataLoader(HybridECGDataset(val_df), batch_size=BATCH_SIZE)\n",
    "\n",
    "# # --- Model, Loss, Optimizer ---\n",
    "# model = FinalMultiInputHybridModel(num_clinical_features=NUM_CLINICAL_FEATURES).to(DEVICE)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE) \n",
    "\n",
    "# criterion = FocalLoss(alpha=alpha_weights, gamma=2.0) \n",
    "\n",
    "# scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=5)\n",
    "\n",
    "# # --- Training Loop ---\n",
    "# print(\"Starting Final Hybrid Training with Focal Loss...\")\n",
    "# best_val_f1 = 0.0\n",
    "\n",
    "# for epoch in range(EPOCHS):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     for (x_signal, x_features), y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "#         x_signal, x_features, y = x_signal.to(DEVICE), x_features.to(DEVICE), y.to(DEVICE)\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         logits = model(x_signal, x_features)\n",
    "#         loss = criterion(logits, y)\n",
    "\n",
    "#         if torch.isnan(loss): continue\n",
    "                \n",
    "#         loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "#         optimizer.step()\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#     avg_loss = total_loss / len(train_loader)\n",
    "#     val_acc, val_f1 = hybrid_evaluate(model, val_loader)\n",
    "    \n",
    "#     scheduler.step(val_f1)\n",
    "\n",
    "#     print(f\"Loss: {avg_loss:.4f} | Val Acc: {val_acc:.4f} | Val F1: {val_f1:.4f}\")\n",
    "#     save_checkpoint(model, epoch + 1, val_f1)\n",
    "\t\n",
    "# \tprint(\"\\n--- Final Evaluation ---\")\n",
    "# if top_checkpoints:\n",
    "#     best_path = top_checkpoints[0][1]\n",
    "#     model.load_state_dict(torch.load(best_path))\n",
    "#     print(f\"Loaded best model from: {best_path}\")\n",
    "\n",
    "# model.eval()\n",
    "# y_true, y_pred = [], []\n",
    "# with torch.no_grad():\n",
    "#     for (x_signal, x_features), y in val_loader:\n",
    "#         x_signal, x_features = x_signal.to(DEVICE), x_features.to(DEVICE)\n",
    "#         out = model(x_signal, x_features)\n",
    "#         preds = torch.argmax(out, dim=1).cpu().numpy()\n",
    "#         y_pred.extend(preds)\n",
    "#         y_true.extend(y.numpy())\n",
    "\t\t\n",
    "# print(\"\\nFinal Classification Report (Hybrid CNN-LSTM):\")\n",
    "# print(classification_report(y_true, y_pred, target_names=[\"Low\", \"Moderate\", \"High\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c2e8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
