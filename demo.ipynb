{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import duckdb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    " \n",
    "BLOOD_MODEL_PATH = 'xgb_cad_severity_model-7.joblib'\n",
    "SCALER_PATH = 'scaler_cad_severity-7.joblib'\n",
    "FEATURES_LIST_PATH = 'selected_features-7.joblib'\n",
    "DUCKDB_PATH = '../../final_db/mimic_analysis.db'\n",
    "ECG_MODEL_PATH = './cnn_lstm_hybrid_checkpoints/hybrid_model_epoch60.pt'\n",
    "CLEANED_CSV_PATH = 'metadata_with_features.csv'\n",
    "FUSION_MODEL_PATH = 'fusion_1_checkpoints/fusion_meta_model.joblib' \n",
    "BATCH_SIZE = 64\n",
    "LEAD_COUNT = 12\n",
    "SAMPLES = 2500\n",
    "NUM_CLASSES = 3\n",
    "NUM_CLINICAL_FEATURES = 8\n",
    "HIDDEN_SIZE = 64\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#ECG Model Architecture & Dataset Classes\n",
    "\n",
    "class CNNLSTM_FeatureExtractor(nn.Module):\n",
    "    def __init__(self, hidden_size=HIDDEN_SIZE, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(LEAD_COUNT, 32, kernel_size=15, stride=2, padding=7),\n",
    "            nn.BatchNorm1d(32), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.Conv1d(32, 64, kernel_size=11, stride=2, padding=5),\n",
    "            nn.BatchNorm1d(64), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.Conv1d(64, 128, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm1d(128), nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=128, hidden_size=hidden_size, num_layers=num_layers,\n",
    "            batch_first=True, bidirectional=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        cnn_out = self.cnn(x)\n",
    "        lstm_input = cnn_out.transpose(1, 2)\n",
    "        _, (h_n, _) = self.lstm(lstm_input)\n",
    "        final_state = torch.cat((h_n[-2, :, :], h_n[-1, :, :]), dim=1)\n",
    "        return final_state\n",
    "\n",
    "class FinalMultiInputHybridModel(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES, num_clinical_features=NUM_CLINICAL_FEATURES):\n",
    "        super().__init__()\n",
    "        self.signal_extractor = CNNLSTM_FeatureExtractor(hidden_size=HIDDEN_SIZE)\n",
    "        INPUT_SIZE = (2 * HIDDEN_SIZE) + num_clinical_features\n",
    "        self.final_fc = nn.Sequential(\n",
    "            nn.Linear(INPUT_SIZE, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, signal, clinical_features):\n",
    "        deep_features = self.signal_extractor(signal)\n",
    "        combined_features = torch.cat((deep_features, clinical_features.float()), dim=1)\n",
    "        return self.final_fc(combined_features)\n",
    "\n",
    "class HybridECGDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # --- Load Signal ---\n",
    "        try:\n",
    "            signal = np.load(row['processed_npy_path']).T\n",
    "            if signal.shape[1] > SAMPLES:\n",
    "                signal = signal[:, :SAMPLES]\n",
    "            elif signal.shape[1] < SAMPLES:\n",
    "                 padding = np.zeros((LEAD_COUNT, SAMPLES - signal.shape[1]), dtype=np.float32)\n",
    "                 signal = np.concatenate([signal, padding], axis=1)\n",
    "            signal = np.nan_to_num(signal, nan=0.0)\n",
    "        except Exception:\n",
    "            signal = np.zeros((LEAD_COUNT, SAMPLES), dtype=np.float32)\n",
    "\n",
    "        # --- Load Clinical Features ---\n",
    "        try:\n",
    "            features = np.load(row['feature_path'])\n",
    "        except Exception:\n",
    "            features = np.zeros(NUM_CLINICAL_FEATURES, dtype=np.float32)\n",
    "\n",
    "        label = 0 # Placeholder if label is unknown\n",
    "        if 'severity_level' in row and pd.notna(row['severity_level']):\n",
    "            label_map = {\"Low\": 0, \"Moderate\": 1, \"High\": 2}\n",
    "            label = label_map.get(row['severity_level'], 0)\n",
    "        \n",
    "        return (torch.tensor(signal, dtype=torch.float32), \n",
    "                torch.tensor(features, dtype=torch.float32)), label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bfe906",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data Loading Function \n",
    "\n",
    "def load_and_align_test_data(cleaned_csv_path, duckdb_path):\n",
    "    \n",
    "    df_ecg_full = pd.read_csv(cleaned_csv_path)\n",
    "    con = duckdb.connect(duckdb_path)\n",
    "    \n",
    "    df_blood_full = con.execute(\"\"\"\n",
    "        SELECT hadm_id, subject_id, anchor_age, gender, cad, severity_level\n",
    "        FROM admissions_severity\n",
    "        WHERE severity_level IS NOT NULL\n",
    "    \"\"\").df()\n",
    "    \n",
    "    cbc_keywords = [\"hemoglobin\", \"hematocrit\", \"rbc\", \"wbc\", \"platelet\", \"mcv\", \"mch\", \"mchc\", \"rdw\", \"neutrophil\", \"lymphocyte\", \"monocyte\", \"eosinophil\", \"basophil\"]\n",
    "    bmp_keywords = [\"sodium\", \"potassium\", \"chloride\", \"bicarbonate\", \"co2\", \"urea\", \"bun\", \"creatinine\", \"glucose\", \"calcium\"]\n",
    "    lft_keywords = [\"albumin\", \"protein\", \"bilirubin\", \"alkaline phosphatase\", \"ast\", \"sgot\", \"alt\", \"sgpt\", \"lactate\"]\n",
    "    lipid_keywords = [\"cholesterol\", \"hdl\", \"ldl\", \"triglyceride\"]\n",
    "    cardiac_keywords = [\"troponin\", \"ck-mb\", \"creatine kinase\", \"ck\", \"bnp\", \"nt-probnp\", \"hs-crp\"]\n",
    "    all_keywords = cbc_keywords + bmp_keywords + lft_keywords + lipid_keywords + cardiac_keywords\n",
    "    pattern = '|'.join(all_keywords)\n",
    "\n",
    "    df_labitems = con.execute(\"SELECT itemid, label, fluid FROM d_labitems WHERE LOWER(fluid) = 'blood'\").df()\n",
    "    mask = df_labitems['label'].str.lower().str.contains(pattern, na=False)\n",
    "    blood_itemids = df_labitems[mask]['itemid'].tolist()\n",
    "    if len(blood_itemids) == 0:\n",
    "        con.close()\n",
    "        raise RuntimeError(\"No matching blood lab items found.\")\n",
    "    blood_itemids_str = ', '.join(map(str, blood_itemids))\n",
    "\n",
    "    df_labs = con.execute(f\"\"\"\n",
    "        SELECT l.subject_id, d.label, AVG(l.valuenum) as mean_value\n",
    "        FROM labevents l JOIN d_labitems d ON l.itemid = d.itemid\n",
    "        WHERE l.itemid IN ({blood_itemids_str})\n",
    "        GROUP BY l.subject_id, d.label\n",
    "    \"\"\").df()\n",
    "    df_labs_pivot = df_labs.pivot(index='subject_id', columns='label', values='mean_value').reset_index()\n",
    "\n",
    "    df_blood_full = pd.merge(df_blood_full, df_labs_pivot, on='subject_id', how='left')\n",
    "\n",
    "    comorb_tables = {\n",
    "        'diabetes': 'diabetes_adm',\n",
    "        'hypertension': 'hypertension_adm',\n",
    "        'renal': 'renal_adm',\n",
    "        'obesity': 'obesity_icd_adm',\n",
    "        'smoker': 'smokers_adm'\n",
    "    }\n",
    "    df_blood_full['hadm_id'] = df_blood_full['hadm_id'].astype(str)\n",
    "\n",
    "    for comorb, table in comorb_tables.items():\n",
    "        df_comorb = con.execute(f\"SELECT DISTINCT hadm_id, 1 AS {comorb} FROM {table}\").df()\n",
    "        if not df_comorb.empty:\n",
    "            df_comorb['hadm_id'] = df_comorb['hadm_id'].astype(str)\n",
    "            df_blood_full = pd.merge(df_blood_full, df_comorb, on='hadm_id', how='left')\n",
    "            df_blood_full[comorb] = df_blood_full[comorb].fillna(0).astype(int)\n",
    "        else:\n",
    "            df_blood_full[comorb] = 0\n",
    "\n",
    "    con.close()\n",
    "    \n",
    "    expected_comorb_cols = list(comorb_tables.keys())\n",
    "    for col in expected_comorb_cols:\n",
    "        if col not in df_blood_full.columns:\n",
    "            df_blood_full[col] = 0\n",
    "\n",
    "    df_blood_full['gender'] = df_blood_full['gender'].map({'M': 0, 'F': 1})\n",
    "    numeric_cols = df_blood_full.select_dtypes(include=['number']).columns.tolist()\n",
    "    median_values = df_blood_full[numeric_cols].median().to_dict()\n",
    "    df_blood_full.fillna(median_values, inplace=True)\n",
    "\n",
    "    try:\n",
    "        feature_names_full = joblib.load(\"feature_names_full-7.joblib\")\n",
    "        selected_features = joblib.load(\"selected_features-7.joblib\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Required joblib artifact missing or unreadable: {e}. Cannot align data.\")\n",
    "    if not isinstance(feature_names_full, list):\n",
    "        feature_names_full = list(feature_names_full)\n",
    "\n",
    "    df_common = pd.merge(\n",
    "        df_blood_full,\n",
    "        df_ecg_full[['subject_id', 'processed_npy_path', 'feature_path']],\n",
    "        on='subject_id', how='inner'\n",
    "    )\n",
    "    df_common = df_common[df_common['severity_level'].isin(['Low', 'Moderate', 'High'])].reset_index(drop=True)\n",
    "    df_common['severity_class'] = df_common['severity_level'].map({'Low': 0, 'Moderate': 1, 'High': 2})\n",
    "\n",
    "    # Splitting to get a representative test set\n",
    "    df_train, df_test_fusion = train_test_split(\n",
    "        df_common,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=df_common['severity_class']\n",
    "    )\n",
    "\n",
    "    for col in expected_comorb_cols:\n",
    "        if col not in df_test_fusion.columns:\n",
    "            df_test_fusion[col] = 0\n",
    "\n",
    "    columns_to_drop_final = ['subject_id', 'hadm_id', 'cad', 'severity_level', 'severity_class', 'processed_npy_path', 'feature_path']\n",
    "    X_blood_all_features = df_test_fusion.drop(columns=[c for c in columns_to_drop_final if c in df_test_fusion.columns], errors='ignore')\n",
    "    X_blood_all_features = X_blood_all_features.reindex(columns=feature_names_full)\n",
    "\n",
    "    for col in X_blood_all_features.columns:\n",
    "        if X_blood_all_features[col].isna().any():\n",
    "            if col in median_values:\n",
    "                X_blood_all_features[col].fillna(median_values[col], inplace=True)\n",
    "            else:\n",
    "                X_blood_all_features[col].fillna(0, inplace=True)\n",
    "\n",
    "    y_test_fusion = df_test_fusion['severity_class'].values\n",
    "    X_ecg_metadata = df_test_fusion\n",
    "    original_feature_names_list = feature_names_full\n",
    "    \n",
    "   \n",
    "    return X_blood_all_features, X_ecg_metadata, y_test_fusion, original_feature_names_list\n",
    "\n",
    "\n",
    "# Prediction Generation (P_A and P_B)\n",
    "\n",
    "\n",
    "def generate_base_predictions(X_blood_raw, X_ecg_metadata, original_feature_names):\n",
    "    \"\"\"Generates P_A (XGBoost probs) and P_B (ECG-LSTM probs).\"\"\"\n",
    "    \n",
    "    model_blood = joblib.load(BLOOD_MODEL_PATH)\n",
    "    scaler = joblib.load(SCALER_PATH)\n",
    "    selected_features = joblib.load(FEATURES_LIST_PATH)\n",
    "    \n",
    "    model_ecg = FinalMultiInputHybridModel(num_clinical_features=NUM_CLINICAL_FEATURES).to(DEVICE)\n",
    "    model_ecg.load_state_dict(torch.load(ECG_MODEL_PATH, map_location=DEVICE))\n",
    "    model_ecg.eval()\n",
    "    \n",
    "    # --- A. Model A: XGBoost Predictions (P_A) ---\n",
    "    X_test_blood_df = X_blood_raw[original_feature_names]\n",
    "    X_test_full_np = X_test_blood_df.values \n",
    "    \n",
    "    # Scale the full 99 features\n",
    "    X_test_scaled_full = scaler.transform(X_test_full_np)\n",
    "    \n",
    "    # Select the final 30 features\n",
    "    X_test_scaled_df = pd.DataFrame(X_test_scaled_full, columns=original_feature_names)\n",
    "    X_test_sel = X_test_scaled_df[selected_features]\n",
    "    \n",
    "    # Predict probabilities\n",
    "    P_A = model_blood.predict_proba(X_test_sel)\n",
    "    \n",
    "\n",
    "    # --- B. Model B: CNN-LSTM Predictions (P_B) ---\n",
    "    ecg_dataset = HybridECGDataset(X_ecg_metadata)\n",
    "    ecg_loader = DataLoader(ecg_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    P_B_list = []\n",
    "    with torch.no_grad():\n",
    "        for (x_signal, x_features), _ in tqdm(ecg_loader, desc=\"ECG Model Prediction\"):\n",
    "            x_signal, x_features = x_signal.to(DEVICE), x_features.to(DEVICE)\n",
    "            logits = model_ecg(x_signal, x_features)\n",
    "            probabilities = F.softmax(logits, dim=1).cpu().numpy()\n",
    "            P_B_list.append(probabilities)\n",
    "            \n",
    "    P_B = np.concatenate(P_B_list, axis=0)\n",
    "   \n",
    "    \n",
    "    # --- C. Create Fusion Input ---\n",
    "    X_fusion = np.hstack((P_A, P_B)) # Shape N x 6 (3 probabilities from Model A + 3 from Model B)\n",
    "    \n",
    "    return X_fusion\n",
    "\n",
    "# Final Fusion Prediction\n",
    "def run_fusion_prediction(X_fusion_input):\n",
    "    \"\"\"Loads the meta-model and makes the final prediction.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        meta_model = joblib.load(FUSION_MODEL_PATH)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"FATAL ERROR: Fusion model file '{FUSION_MODEL_PATH}' not found. Cannot proceed.\")\n",
    "        return None\n",
    "    \n",
    "    y_fusion_pred_numeric = meta_model.predict(X_fusion_input)\n",
    "    \n",
    "    severity_map = {0: 'Low', 1: 'Moderate', 2: 'High'}\n",
    "    y_fusion_pred_label = np.array([severity_map[cls] for cls in y_fusion_pred_numeric])\n",
    "    \n",
    "    \n",
    "    return y_fusion_pred_numeric, y_fusion_pred_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b04e9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ECG Model Prediction: 100%|██████████| 179/179 [03:19<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FINAL LATE FUSION PREDICTION SUMMARY ---\n",
      "\n",
      "First 5 Fused Predictions:\n",
      "   subject_id Predicted_Severity_Label True_Severity_level\n",
      "0    11665092                     High                High\n",
      "1    11173428                     High                High\n",
      "2    11697344                     High                High\n",
      "3    10711042                      Low                 Low\n",
      "4    11568515                     High                High\n"
     ]
    }
   ],
   "source": [
    "#main\n",
    "try:\n",
    "    # 1. Load and align data\n",
    "    X_blood_raw, X_ecg_metadata, y_true_labels, original_feature_names_list = load_and_align_test_data(CLEANED_CSV_PATH, DUCKDB_PATH)\n",
    "\n",
    "    # 2. Generate input for the fusion model (P_A and P_B)\n",
    "    X_fusion_input = generate_base_predictions(X_blood_raw, X_ecg_metadata, original_feature_names_list)\n",
    "\n",
    "    # 3. Make the final prediction with the fusion model\n",
    "    if X_fusion_input is not None:\n",
    "        y_fusion_pred_numeric, y_fusion_pred_label = run_fusion_prediction(X_fusion_input)\n",
    "        \n",
    "        # 4. Display Results\n",
    "        print(\"\\n--- FINAL LATE FUSION PREDICTION SUMMARY ---\")\n",
    "        \n",
    "        # Combine subject IDs and predictions for a summary table\n",
    "        subject_ids = X_ecg_metadata['subject_id'].values\n",
    "        results_df = pd.DataFrame({\n",
    "            'subject_id': subject_ids,\n",
    "            'Predicted_Severity_Label': y_fusion_pred_label,\n",
    "            'True_Severity_level': X_ecg_metadata['severity_level'].values\n",
    "        })\n",
    "        \n",
    "        \n",
    "        print(\"\\nFirst 5 Fused Predictions:\")\n",
    "        print(results_df.head())\n",
    "        \n",
    "     \n",
    "\n",
    "except RuntimeError as e:\n",
    "    print(f\"\\nExecution Failed: {e}\")\n",
    "    print(\"Please ensure all required data files (DuckDB, .joblib, .csv, and .pt) are correctly placed and named.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bfb1669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id Predicted_Severity_Label True_Severity_level\n",
      "5    10485425                 Moderate            Moderate\n",
      "6    11877234                 Moderate            Moderate\n",
      "7    11296936                     High                High\n",
      "8    11576109                     High                High\n",
      "9    10692761                      Low                 Low\n"
     ]
    }
   ],
   "source": [
    "print(results_df[5:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
